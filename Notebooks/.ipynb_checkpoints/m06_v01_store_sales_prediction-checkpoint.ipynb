{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0.0. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:00.501854Z",
     "start_time": "2021-05-13T18:44:57.958551Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dtale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60d8895b5e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdtale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dtale'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import dtale\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import inflection\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import datetime as datetime\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.stats         as stats\n",
    "\n",
    "from tabulate              import tabulate\n",
    "from scipy                 import stats  as ss\n",
    "from boruta                import BorutaPy\n",
    "from matplotlib            import pyplot as plt\n",
    "from IPython.display       import Image\n",
    "from IPython.core.display  import HTML\n",
    "\n",
    "\n",
    "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.linear_model  import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:43:00.539457Z",
     "start_time": "2020-02-25T20:43:00.436593Z"
    },
    "code_folding": [
     0,
     44,
     48,
     52
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "        # start and end date for validation \n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta( days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta( days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop( ['date', 'sales'], axis=1 ) \n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "\n",
    "        # prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1( yhat ) )\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(  m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )\n",
    "\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "     \n",
    "    \n",
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y ) )\n",
    "\n",
    "    \n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    \n",
    "    return pd.DataFrame( { 'Model Name': model_name, \n",
    "                           'MAE': mae, \n",
    "                           'MAPE': mape,\n",
    "                           'RMSE': rmse }, index=[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:02.257914Z",
     "start_time": "2021-05-13T18:45:02.250526Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).to_numpy()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:03.322022Z",
     "start_time": "2021-05-13T18:45:03.310881Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#de matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 0.2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:31.104008Z",
     "start_time": "2021-05-13T18:45:30.026458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sales= pd.read_csv( '../datascience_em_producao/data/train.csv', low_memory=False )\n",
    "df_store = pd.read_csv( '../datascience_em_producao/data/store.csv', low_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:31.749346Z",
     "start_time": "2021-05-13T18:45:31.109382Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# merge\n",
    "df = pd.merge( df_sales, df_store, how='left', on='Store' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1.0. PASSO 01 - DESCRICAO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:31.852382Z",
     "start_time": "2021-05-13T18:45:31.753543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:31.972357Z",
     "start_time": "2021-05-13T18:45:31.857289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:32.073179Z",
     "start_time": "2021-05-13T18:45:31.977014Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.1. Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:32.245911Z",
     "start_time": "2021-05-13T18:45:32.077953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "            'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "\n",
    "#renomear\n",
    "\n",
    "df1.columns = cols_new\n",
    "\n",
    "\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.2. Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:32.488582Z",
     "start_time": "2021-05-13T18:45:32.249869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( 'Número de linhas: {}'.format( df1.shape[0] ) )\n",
    "\n",
    "print( 'Número de colunas: {}'.format( df1.shape[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.3. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:32.972970Z",
     "start_time": "2021-05-13T18:45:32.493252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.3. Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:45:33.450906Z",
     "start_time": "2021-05-13T18:45:32.974539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Date\n",
    "df1['date'] = pd.to_datetime(df1['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.4. Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:24.499791Z",
     "start_time": "2021-05-13T18:45:33.460889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#competition_distance        \n",
    "df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x )\n",
    "                                                                else x )\n",
    "\n",
    "#Logica = valor de distancia muito alto = não existe competição\n",
    "\n",
    "#competition_open_since_month\n",
    "df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) \n",
    "                                                else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "#substituir a data de abertura pela data da competicao se o valor for NA, pois quer dizer que a competição começou no dia em que a loja foi aberta\n",
    "\n",
    "\n",
    "#competition_open_since_year \n",
    "df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] )\n",
    "                                               else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "#mesmo pensamento do mês\n",
    "\n",
    "#promo2_since_week           \n",
    "df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) \n",
    "                                     else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "#mesmo pensamento do ano e mês\n",
    "\n",
    "\n",
    "#promo2_since_year           \n",
    "df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "#mesmo pensamento dos itens anteriores\n",
    "\n",
    "#promo_interval              \n",
    "month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df1['promo_interval'].fillna(0, inplace=True )\n",
    "\n",
    "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:24.840715Z",
     "start_time": "2021-05-13T18:47:24.502653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.5. Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:24.854743Z",
     "start_time": "2021-05-13T18:47:24.845226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:25.126585Z",
     "start_time": "2021-05-13T18:47:24.858360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competiton\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "    \n",
    "# promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:25.306389Z",
     "start_time": "2021-05-13T18:47:25.128828Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:25.660172Z",
     "start_time": "2021-05-13T18:47:25.329062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'float64'] )  #somente valores numericos\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]'] ) #somente valores categoricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "### 1.7.1. Numerical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:25.788255Z",
     "start_time": "2021-05-13T18:47:25.661477Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "print('valores numéricos únicos para cada coluna')\n",
    "num_attributes.apply(lambda x: x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:30.140699Z",
     "start_time": "2021-05-13T18:47:25.790687Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('tabela com tendencia central e de dispersão')\n",
    "# Central Tendency - mean, meadina \n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T \n",
    "d2 = pd.DataFrame( num_attributes.apply( min ) ).T \n",
    "d3 = pd.DataFrame( num_attributes.apply( max ) ).T \n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T \n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T \n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T \n",
    "\n",
    "# concatenar\n",
    "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "round(m,2)\n",
    "\n",
    "\n",
    "#round(num_attributes.describe(),2).T  #outro jeito de calcular a estatística descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "hidden": true
   },
   "source": [
    "### 1.7.2. Categorical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:30.440951Z",
     "start_time": "2021-05-13T18:47:30.142656Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "print('valores categóricos únicos para cada coluna')\n",
    "cat_attributes.apply( lambda x: x.unique().shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:31.375181Z",
     "start_time": "2021-05-13T18:47:30.444103Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "print('box-plot valores categóricos')\n",
    "aux = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.boxplot( x='state_holiday', y='sales', data=aux );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.boxplot( x='store_type', y='sales', data=aux );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.boxplot( x='assortment', y='sales', data=aux );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0. PASSO 02 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:31.493201Z",
     "start_time": "2021-05-13T18:47:31.377008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.1. Mapa Mental de Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:47:31.593172Z",
     "start_time": "2021-05-13T18:47:31.494884Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "Image( 'imagem/MindMapHypothesis.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.2. Criacao das Hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.2.1. Hipoteses Loja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Lojas com número maior de funcionários deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior capacidade de estoque deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com maior porte deveriam vender mais.\n",
    "\n",
    "**4.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**6.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.2.2. Hipoteses Produto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:22:20.284469Z",
     "start_time": "2019-11-16T21:22:20.236577Z"
    },
    "hidden": true
   },
   "source": [
    "**1.** Lojas que investem mais em Marketing deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior exposição de produto deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com produtos com preço menor deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com promoções mais agressivas ( descontos maiores ), deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**8.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2.3. Hipoteses Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:24:09.377189Z",
     "start_time": "2019-11-16T21:24:09.339135Z"
    },
    "hidden": true
   },
   "source": [
    "**1.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**2.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**3.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**4.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**5.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**6.** Lojas deveriam vender menos durante os feriados escolares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2.3. Lista Final de Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**3.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "**8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**12.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**13.** Lojas deveriam vender menos durante os feriados escolares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:44.895439Z",
     "start_time": "2021-05-13T18:47:31.594838Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9f7d9cdca20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "# competition since\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "# state holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:45.096994Z",
     "start_time": "2021-05-13T18:48:44.905870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1. Filtragem das Linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:45.806322Z",
     "start_time": "2021-05-13T18:48:45.103458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#filtramos lojas que não estavam abertas e que não tiveram vendas\n",
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.2. Selecao das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:45.975315Z",
     "start_time": "2021-05-13T18:48:45.807748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#excluímos colunas não relevantes pro negócio\n",
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "\n",
    "\n",
    "df3 = df3.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4.0. PASSO 04 - ANALISE EXPLORATORIA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:46.121807Z",
     "start_time": "2021-05-13T18:48:45.979025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.1. Analise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "### 4.1.1. Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:50.003372Z",
     "start_time": "2021-05-13T18:48:46.125622Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sns.distplot( df4['sales']).set_title('Densidade de Vendas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:50.648411Z",
     "start_time": "2021-05-13T18:48:50.008301Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sns.distplot( df4['sales'], kde=False  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.1.2. Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:54.188455Z",
     "start_time": "2021-05-13T18:48:50.653316Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#Resumo gráfico dos atributos\n",
    "print('distribuição de cada coluna')\n",
    "columns = list(num_attributes.columns)\n",
    "\n",
    "num_attributes.hist(column = columns, bins = 30);\n",
    "\n",
    "\n",
    "# distribuição de cada coluna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:48:57.455195Z",
     "start_time": "2021-05-13T18:48:54.190120Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "num_attributes.hist( bins=25 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "### 4.1.3. Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:07.620567Z",
     "start_time": "2021-05-13T18:48:57.456863Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribuição das variaveis categóricas\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-32ba5ddffc3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# state_holiday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_holiday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'regular_day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_holiday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "print('distribuição das variaveis categóricas')\n",
    "\n",
    "# state_holiday\n",
    "plt.subplot( 3, 2, 1 )\n",
    "a = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot( a['state_holiday'] )\n",
    "\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True );\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True );\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True );\n",
    "\n",
    "# store_type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "sns.countplot( df4['store_type'] );\n",
    "\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', shade=True );\n",
    "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', shade=True );\n",
    "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', shade=True );\n",
    "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', shade=True );\n",
    "\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "sns.countplot( df4['assortment'] );\n",
    "\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', shade=True );\n",
    "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True );\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:17.437825Z",
     "start_time": "2021-05-13T18:49:07.622579Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "plt.subplot( 3, 2, 1 )\n",
    "a = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot( a['state_holiday'] )\n",
    "\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True )\n",
    "\n",
    "# store_type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "sns.countplot( df4['store_type'] )\n",
    "\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', shade=True )\n",
    "\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "sns.countplot( df4['assortment'] )\n",
    "\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.2. Analise Bivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "### **H1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "**FALSA** Lojas com MAIOR SORTIMENTO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:18.591680Z",
     "start_time": "2021-05-13T18:49:17.440850Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index();\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby( ['year_week','assortment'] ).sum().reset_index();\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot();\n",
    "\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:19.707311Z",
     "start_time": "2021-05-13T18:49:18.596934Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index()\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby( ['year_week','assortment'] ).sum().reset_index()\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
    "\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "**FALSA** Lojas com COMPETIDORES MAIS PROXIMOS vendem MAIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:21.395384Z",
     "start_time": "2021-05-13T18:49:19.709747Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby( 'competition_distance' ).sum().reset_index();\n",
    "\n",
    "plt.subplot( 2, 2, 1 )\n",
    "sns.scatterplot( x ='competition_distance', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "bins = list( np.arange( 0, 20000, 1000) )\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins );\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby( 'competition_distance_binned' ).sum().reset_index()\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:22.580688Z",
     "start_time": "2021-05-13T18:49:21.397282Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby( 'competition_distance' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.scatterplot( x ='competition_distance', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "bins = list( np.arange( 0, 20000, 1000) )\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby( 'competition_distance_binned' ).sum().reset_index()\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H3.** Lojas com competidores à mais tempo deveriam vendem mais.\n",
    "**FALSE** Lojas com COMPETIDORES À MAIS TEMPO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:27.055101Z",
     "start_time": "2021-05-13T18:49:22.582495Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plt.subplot( 1, 3, 1 )\n",
    "aux1 = df4[['competition_time_month', 'sales']].groupby( 'competition_time_month' ).sum().reset_index()\n",
    "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & ( aux1['competition_time_month'] != 0 )]\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson'), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:31.483635Z",
     "start_time": "2021-05-13T18:49:27.057837Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plt.subplot( 1, 3, 1 )\n",
    "aux1 = df4[['competition_time_month', 'sales']].groupby( 'competition_time_month' ).sum().reset_index()\n",
    "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & ( aux1['competition_time_month'] != 0 )]\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson'), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "**FALSA** Lojas com promocoes ativas por mais tempo vendem menos, depois de um certo periodo de promocao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:43.042529Z",
     "start_time": "2021-05-13T18:49:31.486196Z"
    },
    "hidden": true,
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8b200792d360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maux1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'promo_time_week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'promo_time_week'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSpec\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df4' is not defined"
     ]
    }
   ],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
    "\n",
    "grid = gridspec.GridSpec( 2, 3 )\n",
    "\n",
    "plt.subplot( grid[0,0] )\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[0,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( grid[1,0] )\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[1,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "\n",
    "plt.subplot( grid[:,2] )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:49:43.399060Z",
     "start_time": "2021-05-13T18:49:43.044505Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
    "\n",
    "grid = GridSpec( 2, 3 )\n",
    "\n",
    "plt.subplot( grid[0,0] )\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[0,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( grid[1,0] )\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[1,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "\n",
    "plt.subplot( grid[:,2] )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### <s>**H5.** Lojas com mais dias de promoção deveriam vender mais.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### **H7.** Lojas com mais promoções consecutivas deveriam vender mais.\n",
    "**FALSA** Lojas com mais promocoes consecutivas vendem menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:16.666087Z",
     "start_time": "2021-05-13T18:52:15.963625Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2'] ).sum().reset_index()\n",
    "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "\n",
    "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "\n",
    "ax.legend( labels=['Tradicional & Extendida', 'Extendida']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:16.770123Z",
     "start_time": "2021-05-13T18:52:16.667575Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2'] ).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:17.380046Z",
     "start_time": "2021-05-13T18:52:16.784501Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "\n",
    "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "\n",
    "ax.legend( labels=['Tradicional & Extendida', 'Extendida']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "### **H8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "**FALSA** Lojas abertas durante o feriado do Natal vendem menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:18.520798Z",
     "start_time": "2021-05-13T18:52:17.383162Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot( 1, 2, 1 )\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby( 'state_holiday' ).sum().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 2, 2 )\n",
    "aux2 = aux[['year', 'state_holiday', 'sales']].groupby( ['year', 'state_holiday'] ).sum().reset_index()\n",
    "sns.barplot( x='year', y='sales', hue='state_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:19.553421Z",
     "start_time": "2021-05-13T18:52:18.522508Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot( 1, 2, 1 )\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby( 'state_holiday' ).sum().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 2, 2 )\n",
    "aux2 = aux[['year', 'state_holiday', 'sales']].groupby( ['year', 'state_holiday'] ).sum().reset_index()\n",
    "sns.barplot( x='year', y='sales', hue='state_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "### **H9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "**FALSA** Lojas vendem menos ao longo dos anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:21.064747Z",
     "start_time": "2021-05-13T18:52:19.558861Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year', 'sales']].groupby( 'year' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:22.369364Z",
     "start_time": "2021-05-13T18:52:21.066846Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year', 'sales']].groupby( 'year' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "### **H10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "**FALSA** Lojas vendem menos no segundo semestre do ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:23.751454Z",
     "start_time": "2021-05-13T18:52:22.371624Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby( 'month' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:25.158973Z",
     "start_time": "2021-05-13T18:52:23.754196Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby( 'month' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "### **H11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "**VERDADEIRA** Lojas vendem mais depois do dia 10 de cada mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:27.168074Z",
     "start_time": "2021-05-13T18:52:25.165505Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7298493a6247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maux1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'day'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maux1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df4' is not defined"
     ]
    }
   ],
   "source": [
    "aux1 = df4[['day', 'sales']].groupby( 'day' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 1 )\n",
    "sns.barplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.regplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
    "aux2 =aux1[['before_after', 'sales']].groupby( 'before_after' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.barplot( x='before_after', y='sales', data=aux2 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:29.917489Z",
     "start_time": "2021-05-13T18:52:27.176990Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day', 'sales']].groupby( 'day' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 1 )\n",
    "sns.barplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.regplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
    "aux2 =aux1[['before_after', 'sales']].groupby( 'before_after' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.barplot( x='before_after', y='sales', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "### **H12.** Lojas deveriam vender menos aos finais de semana.\n",
    "**VERDADEIRA** Lojas vendem menos nos final de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:31.275421Z",
     "start_time": "2021-05-13T18:52:29.929801Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:32.512280Z",
     "start_time": "2021-05-13T18:52:31.277998Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "### **H13.** Lojas deveriam vender menos durante os feriados escolares.\n",
    "**VERDADEIRA** Lojas vendem menos durante os feriadso escolares, except os meses de Julho e Agosto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:33.281032Z",
     "start_time": "2021-05-13T18:52:32.514343Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby( 'school_holiday' ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 1 )\n",
    "sns.barplot( x='school_holiday', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby( ['month','school_holiday'] ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 2 )\n",
    "sns.barplot( x='month', y='sales', hue='school_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:34.019638Z",
     "start_time": "2021-05-13T18:52:33.282944Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby( 'school_holiday' ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 1 )\n",
    "sns.barplot( x='school_holiday', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby( ['month','school_holiday'] ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 2 )\n",
    "sns.barplot( x='month', y='sales', hue='school_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.2.1. Resumo das Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:34.029431Z",
     "start_time": "2021-05-13T18:52:34.022082Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tab =[['Hipoteses', 'Conclusao', 'Relevancia'],\n",
    "      ['H1', 'Falsa', 'Baixa'],  \n",
    "      ['H2', 'Falsa', 'Media'],  \n",
    "      ['H3', 'Falsa', 'Media'],\n",
    "      ['H4', 'Falsa', 'Baixa'],\n",
    "      ['H5', '-', '-'],\n",
    "      ['H7', 'Falsa', 'Baixa'],\n",
    "      ['H8', 'Falsa', 'Media'],\n",
    "      ['H9', 'Falsa', 'Alta'],\n",
    "      ['H10', 'Falsa', 'Alta'],\n",
    "      ['H11', 'Verdadeira', 'Alta'],\n",
    "      ['H12', 'Verdadeira', 'Alta'],\n",
    "      ['H13', 'Verdadeira', 'Baixa'],\n",
    "     ]  \n",
    "print( tabulate( tab, headers='firstrow' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:34.150143Z",
     "start_time": "2021-05-13T18:52:34.030902Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tab =[['Hipoteses', 'Conclusao', 'Relevancia'],\n",
    "      ['H1', 'Falsa', 'Baixa'],  \n",
    "      ['H2', 'Falsa', 'Media'],  \n",
    "      ['H3', 'Falsa', 'Media'],\n",
    "      ['H4', 'Falsa', 'Baixa'],\n",
    "      ['H5', '-', '-'],\n",
    "      ['H7', 'Falsa', 'Baixa'],\n",
    "      ['H8', 'Falsa', 'Media'],\n",
    "      ['H9', 'Falsa', 'Alta'],\n",
    "      ['H10', 'Falsa', 'Alta'],\n",
    "      ['H11', 'Verdadeira', 'Alta'],\n",
    "      ['H12', 'Verdadeira', 'Alta'],\n",
    "      ['H13', 'Verdadeira', 'Baixa'],\n",
    "     ]  \n",
    "print( tabulate( tab, headers='firstrow' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.3. Analise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "### 4.3.1. Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:36.920245Z",
     "start_time": "2021-05-13T18:52:34.153405Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# applying mask\n",
    "mask = np.triu(np.ones_like(num_attributes.corr()))\n",
    "  \n",
    "# plotting a triangle correlation heatmap\n",
    "dataplot = sns.heatmap(num_attributes.corr(), cmap=\"PuOr\", mask=mask, annot = True)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.3.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:41.335197Z",
     "start_time": "2021-05-13T18:52:39.301727Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#Cramer é baseado no qui-quadrado\n",
    "# only categorical data\n",
    "a = df4.select_dtypes( include='object' )\n",
    "\n",
    "# Calculate cramer V\n",
    "a1 = cramer_v( a['state_holiday'], a['state_holiday'] )\n",
    "a2 = cramer_v( a['state_holiday'], a['store_type'] )\n",
    "a3 = cramer_v( a['state_holiday'], a['assortment'] )\n",
    "\n",
    "a4 = cramer_v( a['store_type'], a['state_holiday'] )\n",
    "a5 = cramer_v( a['store_type'], a['store_type'] )\n",
    "a6 = cramer_v( a['store_type'], a['assortment'] )\n",
    "\n",
    "a7 = cramer_v( a['assortment'], a['state_holiday'] )\n",
    "a8 = cramer_v( a['assortment'], a['store_type'] )\n",
    "a9 = cramer_v( a['assortment'], a['assortment'] )\n",
    "\n",
    "# Final dataset\n",
    "d = pd.DataFrame( {'state_holiday': [a1, a2, a3], \n",
    "               'store_type': [a4, a5, a6],\n",
    "               'assortment': [a7, a8, a9]  })\n",
    "d = d.set_index( d.columns )\n",
    "\n",
    "sns.heatmap(d, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:42.854717Z",
     "start_time": "2021-05-13T18:52:41.337255Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ec59fc394c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# only categorical data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate cramer V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcramer_v\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_holiday'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_holiday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df4' is not defined"
     ]
    }
   ],
   "source": [
    "# only categorical data\n",
    "a = df4.select_dtypes( include='object' )\n",
    "\n",
    "# Calculate cramer V\n",
    "a1 = cramer_v( a['state_holiday'], a['state_holiday'] )\n",
    "a2 = cramer_v( a['state_holiday'], a['store_type'] )\n",
    "a3 = cramer_v( a['state_holiday'], a['assortment'] )\n",
    "\n",
    "a4 = cramer_v( a['store_type'], a['state_holiday'] )\n",
    "a5 = cramer_v( a['store_type'], a['store_type'] )\n",
    "a6 = cramer_v( a['store_type'], a['assortment'] )\n",
    "\n",
    "a7 = cramer_v( a['assortment'], a['state_holiday'] )\n",
    "a8 = cramer_v( a['assortment'], a['store_type'] )\n",
    "a9 = cramer_v( a['assortment'], a['assortment'] )\n",
    "\n",
    "# Final dataset\n",
    "d = pd.DataFrame( {'state_holiday': [a1, a2, a3], \n",
    "               'store_type': [a4, a5, a6],\n",
    "               'assortment': [a7, a8, a9]  })\n",
    "d = d.set_index( d.columns )\n",
    "\n",
    "sns.heatmap( d, annot=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5.0. PASSO 05 - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:42.928004Z",
     "start_time": "2021-05-13T18:52:42.856586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 5.1. Normalizacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "NÃO HOUVE NORMALIZAÇÃO, POIS NENHUMA FEATURE TEM DISTRIBUIÇÃO NORMAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "## 5.2. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:43.746020Z",
     "start_time": "2021-05-13T18:52:42.935477Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#Decidindo o rescaling a ser utilizado\n",
    "print('                                                   Rescaling            ')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(df5['competition_distance']).set_title('Competition Distance',  size = 20);\n",
    "\n",
    "#outliers bem definido. Por isso vamos usar o robustscaler\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(df5['competition_time_month']).set_title('Competition Time Month',  size = 20);\n",
    "\n",
    "#outliers bem definido. Por isso vamos usar o robustscaler\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(df5['promo_time_week']).set_title('Promo time Week',  size = 20);\n",
    "#outliers não definido. Por isso vamos usar o MinMaxScaller\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxplot(df5['year']).set_title('Year', size = 20);\n",
    "#outliers não definido. Por isso vamos usar o MinMaxScaller\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:52:44.160957Z",
     "start_time": "2021-05-13T18:52:43.749381Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Usando o robust scaler, pois tira independencia do outlier\n",
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "# competition distance\n",
    "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
    "\n",
    "\n",
    "# competition time month\n",
    "df5['competition_time_month'] = rs.fit_transform( df5[['competition_time_month']].values )\n",
    "\n",
    "# promo time week\n",
    "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
    "\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform( df5[['year']].values )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "### Comparando as dimensões antes do rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:00.672047Z",
     "start_time": "2021-05-13T18:52:44.162411Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('              Comparação das dimensões após e antes o rescaling')\n",
    "\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "sns.distplot(df5['competition_distance']);\n",
    "\n",
    "#outliers bem definido. Por isso vamos usar o robustscaler\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "sns.distplot(df4['competition_distance']);\n",
    "\n",
    "#comparando com antes, vemos que a escala mudou\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "#outliers bem definido. Por isso vamos usar o robustscaler\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "sns.distplot(df5['promo_time_week']);\n",
    "#outliers não definido. Por isso vamos usar o MinMaxScaller\n",
    "plt.subplot(3,2,4)\n",
    "sns.distplot(df4['promo_time_week']);\n",
    "\n",
    "#comparando com antes, vemos que a escala mudou\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "sns.distplot(df5['year']);\n",
    "#outliers não definido. Por isso vamos usar o MinMaxScaller\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "sns.distplot(df4['year']);\n",
    "\n",
    "#comparando com antes, vemos que a escala mudou\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 5.3. Transformacao (enconding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.3.1. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:01.394927Z",
     "start_time": "2021-05-13T18:53:00.673526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# state_holiday - One Hot Encoding\n",
    "df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
    "\n",
    "\n",
    "# assortment - Ordinal Encoding\n",
    "assortment_dict = {'basic': 1,  \n",
    "                   'extra': 2, \n",
    "                   'extended': 3}\n",
    "df5['assortment'] = df5['assortment'].map( assortment_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.3.2. Response Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:05.736325Z",
     "start_time": "2021-05-13T18:53:01.396293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df5['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:09.306275Z",
     "start_time": "2021-05-13T18:53:05.738912Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bb49752d3b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "df5['sales'] = np.log1p( df5['sales'] )\n",
    "\n",
    "sns.distplot(df5['sales'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5.3.3. Nature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:23.495009Z",
     "start_time": "2021-05-13T18:53:09.308228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "# month\n",
    "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "# day \n",
    "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:23.600119Z",
     "start_time": "2021-05-13T18:53:23.497839Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:27:39.152619Z",
     "start_time": "2021-05-11T22:27:39.147435Z"
    }
   },
   "source": [
    "# 6.0. PASSO 06 - FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:24.156686Z",
     "start_time": "2021-05-13T18:53:23.601520Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Dividindo o dataframe em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:24.164792Z",
     "start_time": "2021-05-13T18:53:24.160206Z"
    }
   },
   "outputs": [],
   "source": [
    "# #deletando variaveis que geraram variaveis novas\n",
    "# cols_drop = ['week_of_year', 'day', 'month', 'day_of_week', 'promo_since', 'competition_since', 'year_week' ]\n",
    "# df6 = df6.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Decicindo a data para o treino e para o teste\n",
    "\n",
    "nao pode ser aleatório, pois sabendo os dados do futuro o modelo irá decorar os valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:25.841784Z",
     "start_time": "2021-05-13T18:53:24.169424Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df6[['store', 'date']].groupby('store').min().reset_index()\n",
    "print('primeira data do conjunto de treino é em 02/01/2013')\n",
    "df6[['store', 'date']].groupby('store').max().reset_index()\n",
    "print('última data do conjunto de treino é em 31/07/2015')\n",
    "\n",
    "print('\\n primeira data:', df6[['store', 'date']].groupby('store').max().reset_index()['date'][0] - datetime.timedelta(days = 6*7))\n",
    "\n",
    "print('\\n antes dessa data serão os dados de treino e após essa data serão os dados de teste ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:26.089786Z",
     "start_time": "2021-05-13T18:53:25.844549Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "# test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print( 'Training Min Date: {}'.format( X_train['date'].min() ) )\n",
    "print( 'Training Max Date: {}'.format( X_train['date'].max() ) )\n",
    "\n",
    "print( '\\nTest Min Date: {}'.format( X_test['date'].min() ) )\n",
    "print( 'Test Max Date: {}'.format( X_test['date'].max() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:26.095971Z",
     "start_time": "2021-05-13T18:53:26.092531Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# training and test dataset for Boruta\n",
    "X_train_n = X_train.drop( ['date', 'sales'], axis=1 ).values #pegar todas os valores somente\n",
    "y_train_n = y_train.values.ravel() #usar dentro do vetor\n",
    "\n",
    "# define RandomForestRegressor\n",
    "rf = RandomForestRegressor( n_jobs=-1 )\n",
    "\n",
    "# define Boruta\n",
    "boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit( X_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1. Best Features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:26.264729Z",
     "start_time": "2021-05-13T18:53:26.098858Z"
    }
   },
   "outputs": [],
   "source": [
    "# cols_selected = boruta.support_.tolist()\n",
    "\n",
    "# ## features selecionadas\n",
    "# #criando novo df porque o X_train está com values\n",
    "# X_train_fs = X_train.drop( ['date', 'sales'],baxis=1 )\n",
    "# cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "\n",
    "\n",
    "# ## features nao selecionadas\n",
    "# cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns, cols_selected_boruta ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:26.438409Z",
     "start_time": "2021-05-13T18:53:26.268446Z"
    }
   },
   "outputs": [],
   "source": [
    "# cols_not_selected_boruta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T18:53:26.625018Z",
     "start_time": "2021-05-13T18:53:26.440696Z"
    }
   },
   "outputs": [],
   "source": [
    "#primeiro ciclo vamos usar as seleções do boruta + sin + date + sales\n",
    "\n",
    "cols_selected_boruta = [\n",
    "    'store',\n",
    "    'promo',\n",
    "    'store_type',\n",
    "    'assortment',\n",
    "    'competition_distance',\n",
    "    'competition_open_since_month',\n",
    "    'competition_open_since_year',\n",
    "    'promo2',\n",
    "    'promo2_since_week',\n",
    "    'promo2_since_year',\n",
    "    'competition_time_month',\n",
    "    'promo_time_week',\n",
    "    'day_of_week_sin',\n",
    "    'day_of_week_cos',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'day_sin',\n",
    "    'day_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos']\n",
    "\n",
    "# columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 PASSO 07 -  MODELOS DE MACHINE LEARNING"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
